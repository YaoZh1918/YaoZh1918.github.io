<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[YaoZh1918]]></title>
  <link href="http://yaozh1918.github.io/atom.xml" rel="self"/>
  <link href="http://yaozh1918.github.io/"/>
  <updated>2017-07-14T19:54:56+08:00</updated>
  <id>http://yaozh1918.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[Python实现人工神经网络(1)]]></title>
    <link href="http://yaozh1918.github.io/15000325978554.html"/>
    <updated>2017-07-14T19:43:17+08:00</updated>
    <id>http://yaozh1918.github.io/15000325978554.html</id>
    <content type="html"><![CDATA[
<p>最近刚听完<a href="https://cs231n.github.io">cs231n</a>，突然想自己实现一下神经网络，故开这么一个坑。repo在<a href="https://github.com/YaoZh1918/PyNeuralNet">这里</a>。基本想法就是仿照Tensorflow和Theano实现一个计算图(Computation Graph)，可以自动传梯度。自己写有什么好处呢，其一是开心XD，另外就是可以加深理解，比方说为什么Deconv叫反卷积，为什么有一群人在争论Deconv是不是个好名字，自己写一下Conv和Deconv的forward和backward操作就明白了。</p>

<p>这个系列的第一篇文章就实现下最简单的计算图，都是标量运算，主要理解下BackPropagation的思想。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">BP与Chain Rule</h2>

<p>这里简单讲一下BP的思想，毕竟已经有很多专门介绍的文章了。</p>

<p>考虑一个简单的模型(来源cs231n)：神经网络中的某一个神经元，接受两个输入\(x,y\)，在其内部经过处理，变成\(z=f(x,y)\)，其输出\(z\)再经过若干神经元，变成了网络的最终输出（通常是损失函数的值）\(f_1\circ f_2 \circ\cdots \circ f_k(z, ...)=g(z, ...)=L\)，假设我们已经得到了损失关于\(z\)的偏导\(\frac{\partial L}{\partial z}\)（可以称为上游梯度，upstream gradient，因为也是其他上游神经元传来的），那计算\(\frac{\partial L}{\partial x}\)与\(\frac{\partial L}{\partial y}\)可直接通过链式法则求得：</p>

<p>\[\frac{\partial L}{\partial x}=\frac{\partial L}{\partial z} \frac{\partial z}{\partial x}, \quad <br/>
\frac{\partial L}{\partial y}=\frac{\partial L}{\partial z} \frac{\partial z}{\partial y},\]</p>

<p>其中，\(\frac{\partial z}{\partial x}\)与\(\frac{\partial z}{\partial y}\)可以看作是local gradients，在进行前向传播时就可以算好，缓存在神经元中，这也是为什么会说反向传播需要前向时2倍存储与计算量。</p>

<p>现在我们就得到了这样一个递归的形式，算出来的\(\frac{\partial L}{\partial x}\)与\(\frac{\partial L}{\partial y}\)可以继续反向传给之前的神经元，起始状态也很简单：\(\frac{\partial L}{\partial L}=1\)，这样很方便就可以算出整个网络参数的梯度。</p>

<p><img src="http://o6jlkx4pl.bkt.clouddn.com/15000121481274.jpg" alt=""/></p>

<h2 id="toc_1">标量计算图</h2>

<p>（代码在<a href="https://github.com/YaoZh1918/PyNeuralNet/blob/master/scalar_graph_v1.ipynb">notebook</a>中）</p>

<p>例子就用cs231n中的：</p>

<p>\[f(w,x) = \frac{1}{1 + \exp[-(w_1x_1 + w_2x_2 + b)]}.\]</p>

<p>针对这个问题，我们只需要实现4个运算：加、乘、取逆、指数。也就是说，我们的计算图中只需要这4种运算结点，外加一类输入结点。这些结点最少也要有两个方法：<code>forward()</code>与<code>backward()</code>：</p>

<pre><code>import numpy as np
import abc


class Node(abc.ABC):
    
    @abc.abstractmethod
    def forward(self):
        &quot;&quot;&quot;Feed Forward&quot;&quot;&quot;
    
    @abc.abstractmethod
    def backward(self, dout):
        &quot;&quot;&quot;Back Propagate
        Inputs:
            dout: upstream gradient
        &quot;&quot;&quot;

    @property
    def grads(self):
        return self._grads
</code></pre>

<p>最简单的，Variable类型的结点，可以充当输入、常量（不可更新）或参数（可更新），<code>forward()</code>只需返回当前值，<code>backward()</code>也只是将上流梯度作为自己的梯度即可，不需要继续后向传播，即后向传播递归过程的终止状态。</p>

<pre><code>class Variable(Node):
    
    def __init__(self, val):
        self._v = v
    
    def forward(self):
        return self._v
    
    def backward(self, dout):
        self._grads = dout
</code></pre>

<p>接下来两个二元运算，都接受两个<code>Node</code>，在<code>forward()</code>时，递归调用这两个的<code>forward()</code>方法，获取他们的值，再进行相应计算并返回；<code>backward()</code>时，利用local和upstream梯度算出当前梯度，并向后传播。这里我采用的方法是前向时计算local gradient而不缓存原始数据。</p>

<pre><code>class Add(Node):
    
    def __init__(self, a, b):
        self._a = a
        self._b = b
    
    def forward(self):
        v_a = self._a.forward()
        v_b = self._b.forward()
        # self._local_da = 1.
        # self._local_db = 1.
        return v_a + v_b
    
    def backward(self, dout):
        self._grads = [dout, dout]
        self._a.backward(dout)
        self._b.backward(dout)


class Mul(Node):
    
    def __init__(self, a, b):
        self._a = a
        self._b = b
    
    def forward(self):
        v_a = self._a.forward()
        v_b = self._b.forward()
        self._local_da = v_b
        self._local_db = v_a
        return v_a * v_b
    
    def backward(self, dout):
        da = self._local_da * dout
        db = self._local_db * dout
        self._grads = [da, db]
        self._a.backward(da)
        self._b.backward(db)
</code></pre>

<p>最后两个一元运算也类似：</p>

<pre><code>class Inv(Node):
    
    def __init__(self, a):
        self._a = a
    
    def forward(self):
        val = self._a.forward()
        self._local_grads = - 1. / val**2
        return 1. / val
    
    def backward(self, dout):
        self._grads = self._local_grads * dout
        self._a.backward(self._grads)
        

class Exp(Node):
    
    def __init__(self, a):
        self._a = a
    
    def forward(self):
        val = self._a.forward()
        self._local_grads = np.exp(val)
        return self._local_grads
    
    def backward(self, dout):
        self._grads = self._local_grads * dout
        self._a.backward(self._grads)
</code></pre>

<p>最后我们做下测试：</p>

<pre><code class="language-python3"># Init variables
w1, w2, x1, x2, b = [Variable(float(i)) for i in [2, -3, -1, -2, -3]]

# build graph
logit = Add(Add(Mul(w1, x1), Mul(w2, x2)), b)
f = Inv(Add(Variable(1), Exp(Mul(logit, Variable(-1)))))

# Eval
print(&#39;Values: \n&#39;, logit.forward(), f.forward())
# BP
f.backward(1.0)
print(&#39;Gradients: &#39;)
print(&#39;, &#39;.join(&#39;{:.2f}&#39;.format(v.grads) for v in [w1, w2, x1, x2, b]))
</code></pre>

<blockquote>
<p>Values: <br/>
 1.0 0.73105857863<br/>
Gradients: <br/>
-0.20, -0.39, 0.39, -0.59, 0.20</p>
</blockquote>

<p>对比下正确答案，完美！</p>

<p><img src="http://o6jlkx4pl.bkt.clouddn.com/15000149840268.jpg" alt=""/></p>

<h2 id="toc_2">参数共享</h2>

<p>上面通过递归的方式调用，稍微会有点小问题，一是递归过深python会报错（虽然我们这里不太可能发生），另一点就是参数共享时会出错，考虑这样的一个问题：<br/>
\[f = wx_1 + wx_2\]</p>

<pre><code>w, x1, x2 = [Variable(float(i)) for i in [5, 1, 2]]
f = Add(Mul(w, x1), Mul(w, x2))
print(&#39;Value: \n&#39;, f.forward())
f.backward(1.)
print(&#39;Gradients: \n&#39;, [v.grads for v in [w, x1, x2]])
</code></pre>

<p>输出：</p>

<blockquote>
<p>Value: <br/>
 15.0<br/>
Gradients: <br/>
 [2.0, 5.0, 5.0]</p>
</blockquote>

<p>很明显，关于w的梯度算错了，这是因为w接受自上游的梯度应该相加。具体来说，给定一个计算图，它肯定是有向无环图，在前向传播时，按照拓扑排序来算，后向时则反着来，在未遍历到某个节点前，该结点都只累计上游梯度，不计算，遍历到了再计算，并传播。</p>

<p>上面的代码我们可以稍作修改，主要两点改动：<br/>
1. 维护一个列表，记录结点的创建顺序，即拓扑排序；<br/>
2. 新增propagate方法累积梯度，不传播</p>

<p>这里只改了两个二元运算，完整的代码在<a href="https://github.com/YaoZh1918/PyNeuralNet/blob/master/scalar_graph_v2.ipynb">github</a>中。</p>

<pre><code>import numpy as np
import abc


topo_list = []  # Topological sort

class Node(abc.ABC):
    
    def __init__(self):
        topo_list.append(self)
        self._dout = 0.0
    
    @abc.abstractmethod
    def forward(self):
        &quot;&quot;&quot;Feed Forward&quot;&quot;&quot;
    
    @abc.abstractmethod
    def backward(self):
        &quot;&quot;&quot;Back Propagate&quot;&quot;&quot;
    
    def as_terminal(self):
        &quot;&quot;&quot;Let the node be the terminal &quot;&quot;&quot;
        self._dout = 1.
        return self
    
    def propagte(self, dout):
        &quot;&quot;&quot;Aggregate upstream gradients.&quot;&quot;&quot;
        self._dout += dout

    @property
    def grads(self):
        return self._grads


class Variable(Node):
    
    def __init__(self, val):
        super().__init__()
        self._v = val
    
    def forward(self):
        return self._v
    
    def backward(self):
        self._grads = self._dout

        
class Add(Node):
    
    def __init__(self, a, b):
        super().__init__()
        self._a = a
        self._b = b
    
    def forward(self):
        v_a = self._a.forward()
        v_b = self._b.forward()
        return v_a + v_b
    
    def backward(self):
        dout = self._dout
        self._grads = [dout, dout]
        self._a.propagte(dout)
        self._b.propagte(dout)


class Mul(Node):
    
    def __init__(self, a, b):
        super().__init__()
        self._a = a
        self._b = b
    
    def forward(self):
        v_a = self._a.forward()
        v_b = self._b.forward()
        self._local_da = v_b
        self._local_db = v_a
        return v_a * v_b
    
    def backward(self):
        dout = self._dout
        da = self._local_da * dout
        db = self._local_db * dout
        self._grads = [da, db]
        self._a.propagte(da)
        self._b.propagte(db)
        
</code></pre>

<p>测试:</p>

<pre><code>topo_list = []

w, x1, x2 = [Variable(float(i)) for i in [5, 1, 2]]
f = Add(Mul(w, x1), Mul(w, x2))
print(&#39;Value: \n&#39;, f.forward())

f.as_terminal()
for v in reversed(topo_list):
    v.backward()
print(&#39;Gradients: \n&#39;, [v.grads for v in [w, x1, x2]])
</code></pre>

<blockquote>
<p>Value: <br/>
 15.0<br/>
Gradients: <br/>
 [3.0, 5.0, 5.0]</p>
</blockquote>

<p>完全正确！要注意，因为在实例化时我们把上流梯度设置为了0，在反向传播前，要通过<code>.as_terminal()</code>先将最后一个结点的上流梯度设置为1（即\(\frac{\partial L}{\partial L}=1\))。</p>

<p>不过现在代码还是有点丑陋，功能也很欠缺，那么在下一篇文章中，我们将实现基本的矩阵运算的结点，同时要支持batch，再引入一个类似Tensorflow的Graph来管理计算图。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[利用Ngrok实现内网穿透]]></title>
    <link href="http://yaozh1918.github.io/14836189296241.html"/>
    <updated>2017-01-05T20:22:09+08:00</updated>
    <id>http://yaozh1918.github.io/14836189296241.html</id>
    <content type="html"><![CDATA[
<p>放假快回家了，想着回家就用不了学校的机器了，所以打算内网穿透试一下，折腾一下午总算搞定了。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">前期准备</h2>

<p>首先你要有一台有公网ip的server，同时还要有个域名。server我是用腾讯云学生特惠1块钱搞定的，域名是之前在namecheap上买的，一刀左右一年。server端和client端我都用的是<code>Ubuntu LTS 16.04 64</code>的系统，这样之后编译Ngrok时会方便一些。</p>

<h2 id="toc_1">编译Ngrok</h2>

<p>这一节内容主要参考了这篇文章：<a href="http://www.tuicool.com/articles/ZraURrq">在阿里云搭建自己的ngrok服务</a></p>

<p>因为Ngrok是用go开发的，所以我们需要安装一下go的环境，看github上的说明，还需要装一个<code>mercurial</code>也不知道是什么，都装了肯定不会错。</p>

<pre><code>sudo apt install golang mercurial
</code></pre>

<p>对了，如果是低版本的centos系统，还需要自己升级一下<code>git</code>，<code>yum</code>里的版本比较低，否则后面编译的时候会出错。</p>

<p>之后就是clone下repo，准备编译：</p>

<pre><code>export NGROK_DOMAIN=&quot;ngork.mydomain.com&quot;
git clone https://github.com/inconshreveable/ngrok.git
cd ngrok
</code></pre>

<p>注意把<code>NGROK_DOMAIN</code>替换成自己的域名。</p>

<p>然后生成自签名证书并拷贝到正确的位置：</p>

<pre><code>openssl genrsa -out rootCA.key 2048

openssl req -x509 -new -nodes -key rootCA.key -subj &quot;/CN=$NGROK_DOMAIN&quot; -days 5000 -out rootCA.pem

openssl genrsa -out device.key 2048

openssl req -new -key device.key -subj &quot;/CN=$NGROK_DOMAIN&quot; -out device.csr

openssl x509 -req -in device.csr -CA rootCA.pem -CAkey rootCA.key -CAcreateserial -out device.crt -days 5000

cp rootCA.pem assets/client/tls/ngrokroot.crt

cp device.crt assets/server/tls/snakeoil.crt

cp device.key assets/server/tls/snakeoil.key 
</code></pre>

<p>之后就可以编译server端和client端：</p>

<pre><code>make release-server release-client
</code></pre>

<p>如果server和client系统不一样，需要在前面指定。如生成64位macos客户端：</p>

<pre><code>GOOS=darwin GOARCH=amd64 make release-client
</code></pre>

<p><code>GOOS</code>和<code>GOARCH</code>的取值可通过<code>go env</code>查看。</p>

<p>如果一切顺利，会生成两个文件：<code>ngrokd</code>留在server上，<code>ngrok</code>拷贝到client上。</p>

<h2 id="toc_2">开启server服务</h2>

<p>在server上，通过以下命令开启服务：</p>

<pre><code>export NGROK_DOMAIN=&quot;ngork.mydomain.com&quot;
./ngrokd -domain=&quot;$NGROK_DOMAIN&quot; -httpAddr=&quot;:8001&quot; -httpsAddr=&quot;:8002&quot; -tunnelAddr=&quot;:8443&quot; -log=ngrokd.log -log-level=&quot;INFO&quot; &amp;
</code></pre>

<p><code>domain</code>肯定是要指定的，接下来三个端口可以用默认值，不过我习惯改一下，另外我们希望log输出到文件中，而不是stdout上，最后末尾的<code>&amp;</code>是为了让服务在后台运行。</p>

<h2 id="toc_3">开启client服务</h2>

<p>在client上，我们通过<code>ngrok</code>来实现内网穿透，首先新建<code>~/.ngrok</code>文件，写入以下内容：</p>

<pre><code>server_addr: &quot;ngrok.mydomain.com:8443&quot;
trust_host_root_certs: false
</code></pre>

<p>注意addr后面的端口要与server上的tunnelAddr相同。</p>

<p>当然配置文件也可以另建一个，运行ngrok的时候用<code>-config=</code>传入就好。</p>

<p>现在我们已经可以用了：</p>

<pre><code>./ngrok -subdomain=test 80
</code></pre>

<p>这时ternimal会显示一些内容，当Tunnel Status变为online就连接成功了，这样我们访问<code>http://test.ngrok.mydomain.com:8001</code>就会被指向<code>127.0.0.1:80</code>。程序默认还会创建一个web interface，可以通过<code>127.0.0.1:4040</code>来访问，但没什么用。</p>

<h2 id="toc_4">配置config文件</h2>

<p>如果我们想同时把多个端口映射到server上怎么办？当然可以打开多个<code>ngrok</code>，不过更方便的做法是把它们都写在配置文件中。</p>

<p><a href="https://ngrok.com/docs#multiple-tunnels">官网的材料</a>是关于2.0版本的，而2.0版本没有开源，github上的是1.7版本的，所以写法还不一样，之前一直报错，读了<a href="https://github.com/inconshreveable/ngrok/blob/master/src/ngrok/client/config.go#L124">源码</a>才知道这个地方该怎么写。ps. 配置文件其实是yaml格式的。</p>

<p>比方说我们想创建3个tunnels，一个同时映射80和443端口，一个映射web interface，一个映射22用来ssh连接，我们可以这样写：</p>

<pre><code>server_addr: &quot;ngrok.mydomain.com:8443&quot;
trust_host_root_certs: false
tunnels:
    web-app:
        subdomain: web-app
        proto:
            http: 80
            https: 443
    web-interface:
        subdomain: web-interface
        proto:
            http: 4040
    ssh:
        proto:
            tcp: 22
        remote_port: 8022
</code></pre>

<p>这样如果我想运行其中两个，可以写</p>

<pre><code>./ngrok start web-app ssh
</code></pre>

<p>如果想全部运行，可以写</p>

<pre><code>./ngrok start-all
</code></pre>

<p>这样，我们访问<code>http://wep-app.ngrok.mydomain.com</code>和<code>https://wep-app.ngrok.mydomain.com</code>就可以访问内网架的网页，访问<code>http://web-interface.ngrok.mydomain.com</code>可以访问web interface。注意ssh不需要声明<code>subdomain</code>，但最好给定<code>remote_port</code>，这样ssh就可以这样执行<code>ssh user@ngrok.mydomain.com -p 8022</code>！</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Smooth Thresholding Function]]></title>
    <link href="http://yaozh1918.github.io/14791104542390.html"/>
    <updated>2016-11-14T16:00:54+08:00</updated>
    <id>http://yaozh1918.github.io/14791104542390.html</id>
    <content type="html"><![CDATA[
<p>最近读paper<sup id="fnref1"><a href="#fn1" rel="footnote">1</a></sup>的时候，看到了一个有趣的函数，可以看成thresholding function的一个光滑的近似，故我决定写篇文章简单介绍一下。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">原函数</h2>

<p>文中给出的这个函数是这样的：</p>

<p>\[f(x)=0.25\ln(\cosh(2x))+0.5x+0.17.\]</p>

<p>图像是这样的：</p>

<p><img src="media/14791104542390/origin.png" alt="origin"/></p>

<p>很神奇是不是！但我们还是要研究下这个函数为什么就work？</p>

<p>首先函数中的那个0.17是怎么来的？从图像上观察，应该是进行平移保证整个函数是非负的。</p>

<p>令\(g(x)=\ln \cosh (x) + x\)，这样\(f(x)=\frac{1}{4}g(2x) + 0.17\)。那我们先来看下\(g(x)\)趋于负无穷时的极限：</p>

<p>\[<br/>
\begin{align*}<br/>
 &amp; \lim_{x\to -\infty}\ln \cosh(x) + x \\<br/>
=&amp; \lim_{x\to -\infty} \ln \frac{e^{-x} + e^x}{2} + x \\<br/>
=&amp; \lim_{x\to -\infty} \ln \exp (\ln(e^{-x} + e^x) + x) - \ln 2\\<br/>
=&amp; \lim_{x\to -\infty} \ln(1+e^{2x}) - \ln 2\\<br/>
=&amp; -\ln 2<br/>
\end{align*}<br/>
\]</p>

<p>这样\(\frac{1}{4}g(2x) = -\frac{1}{4}\ln 2\approx -0.17\)，所以这个函数最精确的表达应该是</p>

<p>\[f(x)=0.25\ln(\cosh(2x))+0.5x+0.25\ln2.\]</p>

<h2 id="toc_1">导函数</h2>

<p>接下来我们换个角度，一般的thresholding function是</p>

<p>\[h(x)=\left\{<br/>
\begin{aligned}<br/>
0 &amp; \qquad \mathrm{if}~ x &lt; 0\\<br/>
x &amp; \qquad \mathrm{if}~ x \ge 0,<br/>
\end{aligned}<br/>
\right.<br/>
\]</p>

<p>其导数是<br/>
\[h&#39;(x)=\left\{<br/>
\begin{aligned}<br/>
0 &amp; \qquad \mathrm{if}~ x &lt; 0\\<br/>
1 &amp; \qquad \mathrm{if}~ x &gt; 0.<br/>
\end{aligned}<br/>
\right.<br/>
\]</p>

<p>而这个光滑版的thresholding function的导数是</p>

<p>\[f&#39;(x)=0.5\tanh(2x)+0.5,\]</p>

<p><img src="media/14791104542390/tanh.png" alt="tanh"/></p>

<p>可以看作是\(h&#39;(x)\)的光滑近似，图像上看就是sigmoid形的。它保证了\(x&lt;0\)时，随着\(x\)减小，\(f&#39;(x)\)能很快的下降到接近于0，反映到原函数上就是此时函数几乎无增长；在\(x&gt;0\)时，随着\(x\)增大，\(f&#39;(x)\)能很快的增长到1，这样原函数就有着线性的增长率。</p>

<h2 id="toc_2">设计更多的smooth thresholding functions</h2>

<p>上一节最后给我们提供了一个角度，我们先选择一个长得像sigmoid的函数，然后求积分，就可以得到一个smooth thresholding function。</p>

<p>例如可以取sigmoid函数\(f&#39;(x)=\frac{1}{1+e^x}\)，这样得到\(f(x)=\ln(1+e^x)\).</p>

<div class="footnotes">
<hr/>
<ol>

<li id="fn1">
<p>M.U. Gutmann and A. Hyvärinen. Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics. Journal of Machine Learning Research, 13:307–361, 2012.&nbsp;<a href="#fnref1" rev="footnote">&#8617;</a></p>
</li>

</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ubuntu上安装Transmission Web界面]]></title>
    <link href="http://yaozh1918.github.io/14785830863216.html"/>
    <updated>2016-11-08T13:31:26+08:00</updated>
    <id>http://yaozh1918.github.io/14785830863216.html</id>
    <content type="html"><![CDATA[
<p>考虑到实验室的电脑放着也是浪费，打算装个BT客户端下点种子，同时还可以为我的PT加点流量。但是，实验室的电脑一般就放置在那里，不想动它，最好有个可以远程操控的客户端，经过一番搜寻，打算用Transmission加web界面来实现。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">Install</h2>

<p>首先安装Transmission，Ubuntu的repo里已经有Transmission了，如果想要最新版本也可以添加PPA：</p>

<pre><code>sudo add-apt-repository ppa:transmissionbt/ppa
sudo apt-get update
</code></pre>

<p>之后安装：</p>

<pre><code>sudo apt-get install transmission-cli transmission-common transmission-daemon
</code></pre>

<h2 id="toc_1">Configure</h2>

<p>安装好以后其实已经可以用了，在本地上访问<code>localhost:9091</code>，默认用户名密码都是<code>transmission</code>，但因为白名单的缘故，远程无法访问。为此，我们需要修改位于<code>/var/lib/transmission-daemon/info/settings.json</code>的配置文件。在此之前，记得先停止daemon：</p>

<pre><code>sudo service transmission-daemon stop
</code></pre>

<p>那么在配置文件中，有哪些需要修改呢？<br/>
首先添加白名单并修改账号密码，例如：</p>

<pre><code>&quot;rpc-password&quot;: &quot;password&quot;,
&quot;rpc-username&quot;: &quot;user&quot;,
&quot;rpc-whitelist&quot;: &quot;127.0.0.1,192.168.*.*&quot;,
</code></pre>

<p>注意，默认的密码是SHA1加密后的，我们在修改的时候无需手动加密，直接改就好了，之后重启daemon会自动进行加密。</p>

<p>然后还要修改<code>umask</code>参数，以保证Transmission创建的文件其他用户也可以访问：</p>

<pre><code>&quot;umask&quot;: 2,
</code></pre>

<p>都修改好之后，重启daemon：</p>

<pre><code>sudo service transmission-daemon start
</code></pre>

<p>现在，远程用户（白名单中）可以访问<code>http://server-ip:9091</code>来控制Transmission了。</p>

<h2 id="toc_2">自定义下载位置</h2>

<p>默认的下载位置在<code>/var/lib/transmission-daemon/downloads/</code>，有那么一丝丝不方便，可能需要修改到我们当前用户的<code>Downloads</code>目录下，这一小节就介绍下如何修改下载位置。</p>

<p>首先，出于安全因素，Transmission有自己的一个用户，而现在我们需要让Transmission将文件下载至当前用户的目录下，那么首先需要将当前用户加至组里（假设当前用户叫user）：</p>

<pre><code>sudo usermod -a -G debian-transmission user
</code></pre>

<p>然后我们在当前用户的下载目录中新建一些文件夹，并修改权限：</p>

<pre><code>cd /home/user/Downloads
mkdir transmission
cd transmission
mkdir completed incomplete torrents

sudo chgrp -R debian-transmission /home/user/Downloads/transmission
sudo chmod -R 775 /home/user/Downloads/transmission
</code></pre>

<p>最后修改<code>settings.json</code>:</p>

<pre><code>&quot;download-dir&quot;: &quot;/home/user/Downloads/transmission/completed&quot;,
&quot;incomplete-dir&quot;: &quot;/home/user/Downloads/transmission/incomplete&quot;,
&quot;incomplete-dir-enabled&quot;: true,
&quot;watch-dir&quot;: &quot;/home/user/Downloads/transmission/torrents&quot;,
&quot;watch-dir-enabled&quot;: true
</code></pre>

<p>这样，下载中的文件都会在incomplete中，下载好的在completed中，将种子移至torrents文件夹就会自动开始下载。</p>

<p>收工！</p>

<h2 id="toc_3">Reference</h2>

<p>本文主要参考了以下两篇文章：<br/>
<a href="https://help.ubuntu.com/community/TransmissionHowTo">TransmissionHowTo</a><br/>
<a href="http://www.htpcbeginner.com/install-transmission-web-interface-on-ubuntu-1204/">Install Transmission with web interface on Ubuntu</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[设置Server开机启动ssh服务]]></title>
    <link href="http://yaozh1918.github.io/14776396449421.html"/>
    <updated>2016-10-28T15:27:24+08:00</updated>
    <id>http://yaozh1918.github.io/14776396449421.html</id>
    <content type="html"><![CDATA[
<p>为了能够远程访问server，肯定需要通过ssh，但有时候服务器需要重启，而ssh server是在login后才启动的，也就是说我们需要坐在电脑前，手动登陆一次才能继续使用ssh。今天搜了一下，发现一个简单有效的<a href="http://askubuntu.com/questions/3913/start-ssh-server-on-boot">解决方案</a>。</p>

<span id="more"></span><!-- more -->

<p>其实核心就一条命令，这条命令的作用是设置ssh server在default runlevels时启动。</p>

<pre><code>sudo update-rc.d ssh defaults
</code></pre>

<p>但是此时，我们在图形界面下的Network Manager中修改的如ip地址，网关等是不会生效的。我们要在<code>/etc/network/interfaces</code>添加我们的设置。</p>

<pre><code>auto lo
iface lo inet loopback

auto enp4s0
iface enp4s0 inet static
address 111.111.111.111
netmask 255.255.254.0
gateway 111.111.111.1
dns-nameserver 8.8.8.8
</code></pre>

<p>具体的设置可以参考<a href="http://www.cyberciti.biz/faq/setting-up-an-network-interfaces-file/">这里</a>。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[构建一个可复用的Python实验环境(1)]]></title>
    <link href="http://yaozh1918.github.io/14770379590045.html"/>
    <updated>2016-10-21T16:19:19+08:00</updated>
    <id>http://yaozh1918.github.io/14770379590045.html</id>
    <content type="html"><![CDATA[
<p>毕竟是野路子出身，以前跑实验，总是每一个模型都有一套完整的代码，从读数据，跑模型，算得分，写代码的过程中也是大量复制粘贴，因为读数据和算得分的代码通常都是通用的。<br/>
这次访学，师兄拷给我一份实验环境的代码，看后惊叹原来代码要这样写，耦合解得非常好。但我这种强迫症总是觉得别人写的不漂亮，自己照着重写了一遍，结果并没能领悟其精髓，结果最后跑实验的时候各种出问题。项目好不容易结束，决定认认真真分析一下代码，再重新写一遍。代码在github上同步更新。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">目标</h2>

<p>我们的目标是写一个可复用的实验环境框架，这样拿到一个新的项目，只要对应的填入一些函数、类，就可以使用了。<br/>
那么这个实验环境要有怎样的特性呢？我们希望，在项目进行过程中，如果要添加一个数据集、模型、或是评估指标，只要简单的加入对应的文件就好，而不去影响其他代代码。<br/>
这样的一个环境搭好之后，就可以把它当成一个库来使用，编写额外的代码来调用其中的函数。</p>

<h2 id="toc_1">整体结构</h2>

<p>通常来说，一个完整的实验的流程是读取数据、用模型计算结果、对结果进行评估（打分），那么至少就要有三个基类：<code>dataset</code>,<code>model</code>,<code>metric</code>。此外，我们可能有不同的实验设置，例如80%拿来训练模型，20%作为测试集，这样还需要一个基类<code>setting</code>。最后我们再用一个<code>profile</code>类来把这些东西组装起来就好了。整体的结构就可以这样写：</p>

<pre><code>+explib
|-- +datasets
|-- +models
|-- +metrics
|-- +settings
|-- __init__.py
|-- base.py
|-- utils.py
</code></pre>

<p>我们将基类都定义在<code>base.py</code>中，<code>utils.py</code>放一些常用的小函数，例如io操作等。模型等具体实现写在对应的文件夹下。</p>

<h2 id="toc_2">基类定义</h2>

<p>首先定义整个实验环境的基类，其实没有也可以，这样写更一致一点。</p>

<pre><code>from abc import abstractmethod, ABCMeta
from bunch import Bunch


class expBase(object):
    __metaclass__ = ABCMeta

    def __init__(self):
        self.params = Bunch()
</code></pre>

<p>首先导入<code>abc</code>模块，这样通过声明<code>__metaclass__ = ABCMeta</code>表明当前的<code>class</code>是一个抽象类，无法被直接实例化。<code>expBase</code>继承自<code>object</code>，考虑到所有的子类都可能有参数，我们在<code>__init__</code>中初始化<code>self.params</code>为一个<code>Bunch</code>。<code>Bunch</code>是<code>dict</code>的一个子类，可以用<code>params.x1</code>来代替<code>params[&#39;x1&#39;]</code>，写起来比较方便。</p>

<h3 id="toc_3">dataset and model</h3>

<p>接下来定义关于数据集合模型的基类：</p>

<pre><code>class expDataset(expBase):
    __metaclass__ = ABCMeta

    def __init__(self):
        super(expDataset, self).__init__()

    @abstractmethod
    def load(self):
        &quot;&quot;&quot;Load data
        to be implemented in subclass
        &quot;&quot;&quot;
        return


class expModel(expBase):
    __metaclass__ = ABCMeta

    def __init__(self):
        super(expModel, self).__init__()

    @abstractmethod
    def fit(self, data):
        &quot;&quot;&quot;Fit model to the data
        to be implemented in subclass
        &quot;&quot;&quot;
        return
</code></pre>

<p>我们希望所有的dataset都有一个统一的<code>load</code>接口，可以读取数据并返回，所有的<code>model</code>也要有一个<code>fit</code>接口来将模型用到data上。通过用装饰器<code>abstractmethod</code>声明函数为抽象方法，子类中必须要实现该方法，否则会报错。</p>

<p>这里函数命名<code>fit</code>主要是参考scikit-learn的写法。</p>

<h3 id="toc_4">metric</h3>

<p>接下来定义评估指标的基类：</p>

<pre><code>class expMetric(expBase):
    __metaclass__ = ABCMeta

    def __init__(self):
        super(expMetric, self).__init__()
        self.values = []

    @abstractmethod
    def evaluate(self):
        &quot;&quot;&quot;Evaluate the result
        to be implemented in subclass
        &quot;&quot;&quot;
        return
</code></pre>

<p>其实这一块我还是不太清楚该怎么写，这是之前师兄的写法，这样写考虑的是一般实验都要重复多次取平均值，用一个列表来存每次的结果，这样最后可以返回均值和方差。</p>

<p>这个类有待改进。</p>

<h3 id="toc_5">setting</h3>

<p>实验设置的类：</p>

<pre><code>class expSetting(expBase):
    __metaclass__ = ABCMeta

    def __init__(self):
        super(expSetting, self).__init__()
        self.dataset = None
        self.model = None
        self.metrics = []

    def setup(self, dataset, model, metrics):
        self.dataset = dataset
        self.model = model
        self.metrics = metrics

    @abstractmethod
    def run(self):
        &quot;&quot;&quot;Fit data and evaluate the result
        to be implemented in subclass
        &quot;&quot;&quot;
        return
</code></pre>

<p>要注意的一点是，评估方法可能有多个，所以应该是一个列表。</p>

<h3 id="toc_6">profile</h3>

<p>最后一个类，这个类将4个模块进行拼装并运行：</p>

<pre><code>
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ubuntu安装Nvidia驱动及tensorflow]]></title>
    <link href="http://yaozh1918.github.io/14652179403403.html"/>
    <updated>2016-06-06T20:59:00+08:00</updated>
    <id>http://yaozh1918.github.io/14652179403403.html</id>
    <content type="html"><![CDATA[
<p>刚刚搞了台新机器，带的GTX960显卡，想装个ubuntu跑deep learning，在安装中遇到了一些问题，这里记录一下。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">安装Ubuntu</h2>

<p>用u盘安装<code>64bit 14.04LTS</code>，不知道是不是显示器的原因，960没有vga的口，所以用了个vga转dvi的转接头，导致安装引导一进图形界面显示器就黑屏，显示分辨率超出范围。</p>

<p>因此安装的时候要稍作处理，u盘一进引导就按<code>F1</code>，进入下图的这个界面，然后选择第一个试用或者第二个安装，按<code>F6</code>，可以看到一个参数<code>nomodeset</code>，回车选中，然后再回车开始。然而这个方法对我的电脑不管用，换用第二种方法，按<code>Tab</code>，在启动参数末尾删除<code>--</code>，再加上<code>nomodeset</code>，回车安装，此时分辨率会调整为<code>640x480</code>。</p>

<p><img src="http://o6jlkx4pl.bkt.clouddn.com/2016-06-06-IMG_1360%20copy.jpg" alt="IMG_1360 copy " class="mw_img_center" style="display: block; clear:both; margin: 0 auto;"/></p>

<p>系统装好后，应该还是进不去的，也要调为<code>nomodest</code>，或者简单一点，Grub时选择<code>Advanced-recovery mode-resume</code>。进系统安装nvidia驱动后应该就可以了。</p>

<h2 id="toc_1">安装Nvidia驱动</h2>

<p>安装nvidia驱动尝试了好久才装上去，一开始我是从官网上下载的驱动，安装没问题，但分辨率就被锁在<code>640x480</code>了，折腾了半天，后来发现了一个很方便的安装方法。</p>

<p>打开<code>Additional Drivers</code>，然后直接选中驱动，apply，重启即可。</p>

<p><img src="http://o6jlkx4pl.bkt.clouddn.com/2016-06-06-Screenshot%20from%202016-06-06%2019_30_39.png" alt="Additional Drivers " class="mw_img_center" style="display: block; clear:both; margin: 0 auto;"/></p>

<h2 id="toc_2">安装python</h2>

<p>图省事，我选择了直接安装<a href="https://www.continuum.io/downloads">Anaconda</a>，下载好<code>.sh</code>文件，我用的是2.7的版本，然后terminal执行：</p>

<pre><code>bash ~/Downloads/Anaconda2-4.0.0-Linux-x86_64.sh
</code></pre>

<p>根据提示完成安装。</p>

<p>完成后最好<code>source ~/.bashrc</code>一下。</p>

<h2 id="toc_3">安装Cuda</h2>

<p>首先从nvidia官网上下载<a href="https://developer.nvidia.com/cuda-downloads">Cuda Toolkit</a>和<a href="https://developer.nvidia.com/cudnn">cudnn</a>，其中cuDNN需要注册一个账号。</p>

<p>先安装cuda，我下载的是<code>deb</code>文件，然后安装：</p>

<pre><code>sudo dpkg -i cuda-repo-ubuntu1404-7-5-local_7.5-18_amd64.deb
sudo apt-get update
sudo apt-get install cuda
</code></pre>

<p>现在安装cudnn，按照tensorflow官网提示，安装v5要从源码安装tensorflow才行，懒得搞，直接下载v4版本的。然后复制文件到cuda的目录：</p>

<pre><code>tar xvzf cudnn-7.0-linux-x64-v4.0-prod.tgz
sudo cp cuda/include/* /usr/local/cuda/include
sudo cp cuda/lib64/* /usr/local/cuda/lib64
sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*
</code></pre>

<p>然后在<code>~/.bash_profile</code>中加入：</p>

<pre><code>export LD_LIBRARY_PATH=&quot;$LD_LIBRARY_PATH:/usr/local/cuda/lib64&quot;
export CUDA_HOME=/usr/local/cuda
</code></pre>

<p>最后再更新一下：<code>source .bash_profile</code>。</p>

<h2 id="toc_4">安装Tensorflow</h2>

<p>准备工作都已搞定，最后安装tensorflow即可，官网给出了anaconda环境的<a href="https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#anaconda-environment-installation">安装方法</a>，但我想把tensorflow安装到全局，而不是一个环境中，所以直接用pip安装即可。</p>

<p>（下午第一次装的时候还是0.8的教程，晚上写这篇文章的时候就更新到了0.9...）</p>

<p>找到gpu版本的地址：</p>

<pre><code>$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0rc0-cp27-none-linux_x86_64.whl
</code></pre>

<p>然后用<code>pip</code>安装，注意我们要用anaconda中的pip：</p>

<pre><code>$ sudo ~/anaconda2/bin/pip install --ignore-installed --upgrade $TF_BINARY_URL
</code></pre>

<p>其中，<code>--ignore-installed</code>是因为<code>easy_install</code>会报错。</p>

<h2 id="toc_5">Test</h2>

<p>至此，已全部安装好了！让我们来测试一下！</p>

<pre><code>python -c &#39;import tensorflow&#39;
</code></pre>

<p>看到全是successfully opened...就可以了！</p>

<p>也可以跑个cnn试一下：</p>

<pre><code>python -m tensorflow.models.image.mnist.convolutional
</code></pre>

<p>gpu就是快啊，我的rmbp每步是要290ms左右，现在只要12ms，不说了，跑cnn去了XD</p>

<h2 id="toc_6">Error</h2>

<p>2016-6-22更新：</p>

<p>有段时间没用，突然出现了这样的问题：</p>

<pre><code>libcudart.so.7.5: cannot open shared object file: No such file or directory
</code></pre>

<p>解决方案：</p>

<pre><code>sudo ldconfig /usr/local/cuda/lib64
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MongoDB安装及pymongo入门]]></title>
    <link href="http://yaozh1918.github.io/14641625300131.html"/>
    <updated>2016-05-25T15:48:50+08:00</updated>
    <id>http://yaozh1918.github.io/14641625300131.html</id>
    <content type="html"><![CDATA[
<p>在自己的ubuntu上装MongoDB时遇到了一些问题，装好也不太会用，写篇文章记录下吧！</p>

<span id="more"></span><!-- more -->

<ul>
<li>
<a href="#toc_0">安装</a>
</li>
<li>
<a href="#toc_1">启动/停止服务</a>
</li>
<li>
<a href="#toc_2">PyMongo</a>
<ul>
<li>
<a href="#toc_3">Installation</a>
</li>
<li>
<a href="#toc_4">Tutorial</a>
<ul>
<li>
<a href="#toc_5">Making a connection</a>
</li>
<li>
<a href="#toc_6">Database</a>
</li>
<li>
<a href="#toc_7">Collection</a>
</li>
<li>
<a href="#toc_8">Documents</a>
<ul>
<li>
<a href="#toc_9">insert</a>
</li>
<li>
<a href="#toc_10">find</a>
</li>
<li>
<a href="#toc_11">sort</a>
</li>
<li>
<a href="#toc_12">update</a>
</li>
<li>
<a href="#toc_13">remove</a>
</li>
</ul>
</li>
<li>
<a href="#toc_14">Aggregation</a>
</li>
<li>
<a href="#toc_15">Indexes</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>


<h2 id="toc_0">安装</h2>

<p>我的系统是<code>Ubuntu 14.04.4 LTS</code>.</p>

<p>安装还是按照<a href="https://docs.mongodb.com/manual/tutorial/install-mongodb-on-ubuntu/">官方教程</a>比较好，虽然<code>ubuntu</code>的<code>apt-get</code>中有个<code>mongodb</code>，但我们用的不是这个。</p>

<p>安装过程也比较无脑，照着做就好了：</p>

<pre><code>sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv EA312927
echo &quot;deb http://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/3.2 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-3.2.list
sudo apt-get update
sudo apt-get install -y mongodb-org
</code></pre>

<p>注意第一句是要导入一个<code>GPG Key</code>，不同版本不一样，实际装的时候去官网看一眼。</p>

<h2 id="toc_1">启动/停止服务</h2>

<p>安装好后就可以启动停止mongodb的服务了：</p>

<pre><code>sudo service mongod start
sudo service mongod stop
sudo service mongod restart
</code></pre>

<p>注意这里的<code>mongod</code>指代的是mongodb的deamon。</p>

<h2 id="toc_2">PyMongo</h2>

<p>感觉shell不是很给力，就直接看pymongo的教程吧，下面是按照<a href="https://docs.mongodb.com/getting-started/python/">官网</a>的教程，和api的<a href="http://api.mongodb.com/python/current/index.html">文档</a>整理写的一些基本函数。</p>

<p>首先导入官网给出的一个数据，我们后面的教程都会在这个数据上操作：</p>

<pre><code>wget https://raw.githubusercontent.com/mongodb/docs-assets/primer-dataset/primer-dataset.json
mongoimport --db test --collection restaurants --drop --file primer-dataset.json
</code></pre>

<p>第一行是下载文件，第二行是将数据导入到名为test的database中名为restaurants的collection中。</p>

<h3 id="toc_3">Installation</h3>

<p>安装就用<code>pip</code>：</p>

<pre><code>sudo pip install pymongo
</code></pre>

<h3 id="toc_4">Tutorial</h3>

<p>首先导入module：</p>

<pre><code>from pymongo import MongoClient
</code></pre>

<h4 id="toc_5">Making a connection</h4>

<p>利用<code>MongoClient</code>创建一个cursor，参数是可以为空的，默认会连接到<code>localhost:27017</code>，也就是说以下三句效果相同：</p>

<pre><code>client = MongoClient()
client = MongoClient(&#39;localhost&#39;, 27017)
client = MongoClient(&#39;mongodb://localhost:27017/&#39;)
</code></pre>

<h4 id="toc_6">Database</h4>

<p>创建好连接后就可以对数据库进行操作了，例如想看所有的数据库：</p>

<pre><code>client.database_names()
</code></pre>

<p>一般来说会看到一个叫<code>test</code>的数据库。</p>

<p>连接到一个数据库有两种方法，第二种方法类似dict，如果数据库名有特殊字符就只能用这种。</p>

<pre><code>db = client.test
db = client[&#39;a-database&#39;]
</code></pre>

<p>注意，MongoDB<strong>无需显式创建数据库</strong>，例如上面的代码，<code>a-database</code>如果不存在，此时会自动创建一个（其实也不是，只有真正对这个数据库进行操作后才会创建）。</p>

<p>如果要删除一个database，则需要在<code>client</code>中操作：</p>

<pre><code>db.drop_database(&#39;a_database&#39;)
</code></pre>

<p>现在我们进入<code>test</code>数据库进行后续的教程。</p>

<h4 id="toc_7">Collection</h4>

<p>因为<code>MongoDB</code>是<code>NoSQL</code>的，有一些概念与传统的RDBMS有区别，比如这个<code>collection</code>就类似于RDBMS中的关系表<code>table</code>，<code>table</code>是记录<code>row</code>的集合，而<code>collection</code>是<code>document</code>的集合。</p>

<p>和操作database很像，两种连接方式，无须显式创建。</p>

<pre><code>db.collection_names()  # 查看当前数据库下的所有collection
collection = db.restaurants
collection = db[&#39;restaurants&#39;]
</code></pre>

<p>类似的，删除<code>collection</code>要在database中进行：</p>

<pre><code>db.drop_collection(&#39;a_collection&#39;)
</code></pre>

<h4 id="toc_8">Documents</h4>

<p><code>MongoDB</code>中的数据都是以一种类似<code>JSON</code>的文档<code>document</code>存储的，类似RDBMS中的记录／行<code>row</code>，不同的是，一个collection中的documents可以有不同的域<code>field</code>，而一张表中的行必须有相同的属性／列<code>column</code>。</p>

<p>document按照类<code>JSON</code>的格式存，在<code>python</code>中就会表示为<code>dict</code>，例如下面就是一个document的内容：</p>

<pre><code>from datetime import datetime
d = {
        &quot;address&quot;: {
            &quot;street&quot;: &quot;2 Avenue&quot;,
            &quot;zipcode&quot;: &quot;10075&quot;,
            &quot;building&quot;: &quot;1480&quot;,
            &quot;coord&quot;: [-73.9557413, 40.7720266]
        },
        &quot;borough&quot;: &quot;Manhattan&quot;,
        &quot;cuisine&quot;: &quot;Italian&quot;,
        &quot;grades&quot;: [
            {
                &quot;date&quot;: datetime.strptime(&quot;2014-10-01&quot;, &quot;%Y-%m-%d&quot;),
                &quot;grade&quot;: &quot;A&quot;,
                &quot;score&quot;: 11
            },
            {
                &quot;date&quot;: datetime.strptime(&quot;2014-01-16&quot;, &quot;%Y-%m-%d&quot;),
                &quot;grade&quot;: &quot;B&quot;,
                &quot;score&quot;: 17
            }
        ],
        &quot;name&quot;: &quot;Vella&quot;,
        &quot;restaurant_id&quot;: &quot;41704620&quot;
    }
)
</code></pre>

<p>假设我们现在的collection就是一开始添加的<code>restaurants</code>，可以先看看有多少documents：</p>

<pre><code>collection.count()
</code></pre>

<h5 id="toc_9">insert</h5>

<p>现在将上面的那个document插入：</p>

<pre><code>result = collection.insert_one(d)
result.inserted_id
</code></pre>

<p>注意会返回一个<code>InsertOneResult</code>类型的数据，其有个属性<code>inserted_id</code>会给出插入的document在collection中的id号，对于一个collection中各个documents都是不同的，如果插入时没有给定，则会自动创建。</p>

<p>如果想一次插入多个，可以用<code>insert_many</code>：</p>

<pre><code>result = collection.insert_many([d1, d2, d3])
result.inserted_ids
</code></pre>

<p>类似的，会返回一个<code>InsertManyResult</code>类的数据，可以看所有documents的id。</p>

<h5 id="toc_10">find</h5>

<p>本小节会介绍两个函数<code>find</code>和<code>find_one</code>，从函数名就可以猜出，<code>find</code>会找出所有符合条件的documents，其返回的数据类型为<code>Cursor</code>，实际上就是一个<code>iterator</code>，需要迭代访问；而<code>find_one</code>只会返回第一个满足条件的document，数据类型是<code>dict</code>。</p>

<pre><code>cursor = find()  # 条件为空，也就是会返回所有的documents
for doc in cursor:  # 迭代访问
    print doc
find_one()  # 返回第一个document
</code></pre>

<p>还是拿<code>restaurants</code>做示范，如果要找<code>borough</code><strong>等于</strong><code>Manhattan</code>的，将条件按<code>dict</code>格式传进去：</p>

<pre><code>cursor = db.restaurants.find({&quot;borough&quot;: &quot;Manhattan&quot;})
</code></pre>

<p><code>dict</code>可以嵌套<code>dict</code>，同样的<code>document</code>也可以嵌套<code>document</code>，例如<code>address</code>下还有<code>street</code>、<code>zipcode</code>等，如果要找<code>zipcode</code>等于<code>10075</code>的，则要用<code>.</code>来连接：</p>

<pre><code>cursor = db.restaurants.find({&quot;address.zipcode&quot;: &quot;10075&quot;})
</code></pre>

<p>一家餐厅可能有多个用户打分，这就形成了一个documents的列表，<code>grades</code>就是这样，如果想找<code>grades</code>中是否<strong>包含</strong>一个document的<code>grade</code><strong>等于</strong><code>B</code>，则可以这样实现：</p>

<pre><code>cursor = db.restaurants.find({&quot;grades.grade&quot;: &quot;B&quot;})
</code></pre>

<p>如果涉及到操作符，如大于小于，则用下面这种格式（dict套dict）：</p>

<pre><code>{ &lt;field1&gt;: { &lt;operator1&gt;: &lt;value1&gt; } }
</code></pre>

<p>比如</p>

<pre><code>cursor = db.restaurants.find({&quot;grades.score&quot;: {&quot;$gt&quot;: 30}})
</code></pre>

<p>具体的操作符可以去看<a href="https://docs.mongodb.com/manual/reference/operator/">官方文档</a>。</p>

<p><code>AND</code>操作很简单，只要将多个条件写在dict中就好：</p>

<pre><code>cursor = db.restaurants.find({&quot;cuisine&quot;: &quot;Italian&quot;, &quot;address.zipcode&quot;: &quot;10075&quot;})
</code></pre>

<p><code>OR</code>则比较特殊，dict中用<code>$or</code>作为key，条件写在list中作value：</p>

<pre><code>cursor = db.restaurants.find(
    {&quot;$or&quot;: [{&quot;cuisine&quot;: &quot;Italian&quot;}, {&quot;address.zipcode&quot;: &quot;10075&quot;}]})
</code></pre>

<p><code>find_one</code>与上面类似，就不多说了，唯一的区别就是返回的是一个dict。</p>

<h5 id="toc_11">sort</h5>

<p>查询到多个结果后可能希望对结果排序，那么就要对<code>Cursor</code>用<code>sort</code>，比如希望先按<code>borough</code>升序，再按<code>zipcode</code>升序，可以写为：</p>

<pre><code>cursor = db.restaurants.find().sort([
    (&quot;borough&quot;, pymongo.ASCENDING),
    (&quot;address.zipcode&quot;, pymongo.ASCENDING)
])
</code></pre>

<p>如果只按照一个属性排序，则直接将属性和方向传入即可：</p>

<pre><code>cursor = db.restaurants.find().sort(&quot;borough&quot;, pymongo.ASCENDING)
</code></pre>

<p>注意，<code>sort</code>是inplace的，虽然也会返回一个<code>Cursor</code>，但假如已经查询完返回了一个<code>Cursor</code>，则下面两句代码没有区别：</p>

<pre><code>cursor = cursor.sort(&quot;borough&quot;, pymongo.ASCENDING)
cursor.sort(&quot;borough&quot;, pymongo.ASCENDING)
</code></pre>

<h5 id="toc_12">update</h5>

<p>类似的，本节也有两个函数<code>update_one</code>和<code>update_many</code>。</p>

<p>只需将查询条件和更新内容作为两个参数传入即可，例如修改<code>cuisine</code>为<code>American (New)</code>（用到<code>$set</code>），修改<code>lastModified</code>为当前时间（用到<code>$currentDate</code>）：</p>

<pre><code>result = db.restaurants.update_one(
    {&quot;name&quot;: &quot;Juni&quot;},
    {
        &quot;$set&quot;: {
            &quot;cuisine&quot;: &quot;American (New)&quot;
        },
        &quot;$currentDate&quot;: {&quot;lastModified&quot;: True}
    }
)
result.matched_count  # 查找到的数量
result.modified_count  # 实际修改的数量
</code></pre>

<p>这个部分也有好多操作符，还是推荐去扫一遍<a href="https://docs.mongodb.com/manual/reference/operator/">官方文档</a>。</p>

<p>这个是更新，如果要进行替换，可以用<code>replace_one</code>（并没有<code>replace_many</code>），第一个参数为条件，第二个参数为替换内容，替换后只有<code>_id</code>会保留。</p>

<h5 id="toc_13">remove</h5>

<p>要删除document也有两个函数，<code>delete_one</code>和<code>delete_many</code>，只需传入查询条件即可，返回的结果可以查看实际删除的数量：</p>

<pre><code>result = db.restaurants.delete_many({&quot;borough&quot;: &quot;Manhattan&quot;})
result.deleted_count
</code></pre>

<p>如果要删除所有，则可以传入条件<code>{}</code>（为什么不drop掉collection呢？）</p>

<h4 id="toc_14">Aggregation</h4>

<p>聚合这一块内容很复杂，通过<code>aggregate</code>可以实现SQL中的<code>group by</code>、<code>having</code>等功能，在3.2版本后，还可以实现<code>join</code>操作！坑比较大，等有空再单独写一章吧。</p>

<h4 id="toc_15">Indexes</h4>

<p><code>index</code>主要是用来加速特定查找的，如果没有索引，每次查找就要遍历一遍collection，效率自然不高。<code>MongoDB</code>会自动把索引建在<code>_id</code>上，通常对我们的查找没有帮助，需要我们手动选择一个field建立，当然也可以选择一组fields建立：</p>

<pre><code>db.restaurants.create_index([
    (&quot;cuisine&quot;, pymongo.ASCENDING),
    (&quot;address.zipcode&quot;, pymongo.DESCENDING)
])
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Installing Pygame on Mac OS X]]></title>
    <link href="http://yaozh1918.github.io/14623285310444.html"/>
    <updated>2016-05-04T10:22:11+08:00</updated>
    <id>http://yaozh1918.github.io/14623285310444.html</id>
    <content type="html"><![CDATA[
<p>It&#39;s said that <code>pygame</code> provided on their <a href="http://www.pygame.org/download.shtml">website</a> is not compatible with Mac system python because <code>pygame</code> is built for 32 bit python while system python is 64 bit. </p>

<span id="more"></span><!-- more -->

<p>Luckily I have found a <a href="https://bitbucket.org/pygame/pygame/issues/82/homebrew-on-leopard-fails-to-install#comment-627494">solution</a> and now I post it on my blog in case I forget it.</p>

<pre><code>brew install mercurial
brew install sdl sdl_image sdl_mixer sdl_ttf smpeg portmidi 
sudo pip install hg+http://bitbucket.org/pygame/pygame
</code></pre>

<p>After installation, you can validate it via this interesting <a href="https://github.com/sourabhv/FlapPyBird">repo</a>.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sort 3x3 grid by rotating 2x2 subgrids]]></title>
    <link href="http://yaozh1918.github.io/14621764503901.html"/>
    <updated>2016-05-02T16:07:30+08:00</updated>
    <id>http://yaozh1918.github.io/14621764503901.html</id>
    <content type="html"><![CDATA[
<p>Given a 3x3 grid filled with 1-9, how do you sort it to another given grid by rotating 2x2 subgrids?</p>

<p>Some discussions can be found <a href="http://stackoverflow.com/questions/23433442/sort-3x3-grid-by-rotating-2x2-subgrids">here</a>.</p>

<span id="more"></span><!-- more -->

<pre><code>import numpy as np
from Queue import Queue


class Sort_Grid:

    def __init__(self, S=123456789, T=947852361):
        self.source = S
        self.terminal = T

    def num2array(self, num):
        ret = np.zeros(9, np.uint8)
        for i in xrange(9):
            ret[i] = num / 10**(8-i)
            num -= ret[i] * 10**(8-i)
        return ret

    def array2num(self, arr):
        return np.sum(arr * 10**np.arange(8,-1,-1))

    def biBFS(self):
        self.basis = [[0,0], [0,1], [1,0], [1,1]]
        self.subbasis = [[1,3,0,2], [2,0,3,1]]
        self.lookup = [np.zeros(987654321+1, bool) for i in range(2)]
        self.queue = [Queue() for i in range(2)]
        self.lookup[0][self.source] = True
        self.lookup[1][self.terminal] = True
        level0 = 0
        level1 = 0
        c0 = self.source
        c1 = self.terminal
        if c0 == c1:
            return 0, 0, 0
        while True:
            if level0 &lt; level1:
                midstate = self.EnQueue(c0, level0, 0)
                if midstate:
                    return midstate, level0, level1
                c0, level0 = self.queue[0].get()
            else:
                midstate = self.EnQueue(c1, level1, 1)
                if midstate:
                    return midstate, level0, level1
                c1, level1 = self.queue[1].get()

    def EnQueue(self, state, level, ind):
        array = self.num2array(state)
        for i in range(4):
            shadow = array.copy()
            x, y = self.basis[i]
            base = np.array([x*3+y, x*3+y+1, (x+1)*3+y, (x+1)*3+y+1])
            for j in range(2):
                shadow[base] = array[base[self.subbasis[j]]]
                num = self.array2num(shadow)
                if ~self.lookup[ind][num]:
                    if self.lookup[1-ind][num]:
                        return num
                    self.queue[ind].put((num, level+1))
                    self.lookup[ind][num] = True

def biBFS(S, T, seqlist):
    if S == T:
        return
    mid, l0, l1 = Sort_Grid(S, T).biBFS()
    if mid==0 or mid in seqlist:
        return
    seqlist.insert(seqlist.index(S)+1, mid)
    biBFS(S, mid, seqlist)
    biBFS(mid, T, seqlist)

def main():
    S = 123456789
    T = 947852361
    seqlist = [S, T]
    biBFS(S, T, seqlist)
    return seqlist

if __name__ == &#39;__main__&#39;:
    main()

</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[开博客啦！]]></title>
    <link href="http://yaozh1918.github.io/14621706709086.html"/>
    <updated>2016-05-02T14:31:10+08:00</updated>
    <id>http://yaozh1918.github.io/14621706709086.html</id>
    <content type="html"><![CDATA[
<p>终于开了一个博客，感谢有<code>MWeb</code>这么好用的软件。</p>

<p>之前一直用的作业部落的<code>Cmd Markdown</code>，也很不错，也感谢一下XD。但比起<code>MWeb</code>还是逊色不少，这个可以直接生成静态页面，几步就可以挂到<code>Github Pages</code>上了，方便的很！图片、URL什么的插入都很方便。安利一波！</p>

<span id="more"></span><!-- more -->

<p>那么这个博客就主要记录一下关于Machine Learning, Data Mining的一些内容吧，可能还会有一些基本的算法、编程语言、数学的内容。</p>

<p>接下来的内容仅仅是测试一下各项功能是否正常。</p>

<ul>
<li>
<a href="#toc_0">LaTex</a>
</li>
<li>
<a href="#toc_1">Sequence and Flow Chart</a>
</li>
<li>
<a href="#toc_2">Images</a>
</li>
</ul>


<h2 id="toc_0">LaTex</h2>

<p>For example this is a Block level \[x = {-b \pm \sqrt{b^2-4ac} \over 2a}\] formula, and this is an inline Level \(x = {-b \pm \sqrt{b^2-4ac} \over 2a}\) formula.</p>

<p>\[ \frac{1}{\Bigl(\sqrt{\phi \sqrt{5}}-\phi\Bigr) e^{\frac25 \pi}} =<br/>
1+\frac{e^{-2\pi}} {1+\frac{e^{-4\pi}} {1+\frac{e^{-6\pi}}<br/>
{1+\frac{e^{-8\pi}} {1+\ldots} } } } \]</p>

<h2 id="toc_1">Sequence and Flow Chart</h2>

<pre><code class="language-sequence">Andrew-&gt;China: Says Hello
Note right of China: China thinks about it
China--&gt;Andrew: How are you?
Andrew-&gt;&gt;China: I am good thanks!
</code></pre>

<pre><code class="language-flow">st=&gt;start: Start:&gt;http://www.google.com[blank]
e=&gt;end:&gt;http://www.google.com
op1=&gt;operation: My Operation
sub1=&gt;subroutine: My Subroutine
cond=&gt;condition: Yes
or No?:&gt;http://www.google.com
io=&gt;inputoutput: catch something...

st-&gt;op1-&gt;cond
cond(yes)-&gt;io-&gt;e
cond(no)-&gt;sub1(right)-&gt;op1
</code></pre>

<h2 id="toc_2">Images</h2>

<p>My avatar.</p>

<p><img src="http://ooo.0o0.ooo/2016/05/02/5726ffee18657.jpg" alt="icon"/></p>

<p>Resize and center.</p>

<p><img src="http://ooo.0o0.ooo/2016/05/02/5726ffee18657.jpg" alt="icon" class="mw_img_center" style="width:100px;display: block; clear:both; margin: 0 auto;"/></p>

]]></content>
  </entry>
  
</feed>
