<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Research on Ylog</title>
    <link>https://yzhang1918.github.io/categories/research/</link>
    <description>Recent content in Research on Ylog</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>©2020 yzhang1918</copyright>
    <lastBuildDate>Mon, 17 Feb 2020 20:51:33 +0800</lastBuildDate>
    
	<atom:link href="https://yzhang1918.github.io/categories/research/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>图卷积GCN的直观理解</title>
      <link>https://yzhang1918.github.io/posts/gcn_intuition/</link>
      <pubDate>Mon, 17 Feb 2020 20:51:33 +0800</pubDate>
      
      <guid>https://yzhang1918.github.io/posts/gcn_intuition/</guid>
      <description>实验室又有新生进来了，也有对图卷积感兴趣的，那就写篇文章，简单的讲一下。本篇文章参考了Kipf的博客，主要是直观的理解，加上我的一点解读，数</description>
    </item>
    
    <item>
      <title>Soft Policy Iteration</title>
      <link>https://yzhang1918.github.io/posts/sac/</link>
      <pubDate>Thu, 02 Jan 2020 20:17:15 +0800</pubDate>
      
      <guid>https://yzhang1918.github.io/posts/sac/</guid>
      <description>This is a note on the soft policy iteration from SAC12.
 Soft Policy Evaluation Soft Policy Improvement Soft Policy Iteration Other References    Soft Policy Evaluation We define the bellman backup operator for any $Q: \mathcal{S\times A} \rightarrow \Re$:
 $$ \mathcal{T}^\pi Q(s_t, a_t) \triangleq r(s_t, a_t) + \gamma \mathbb{E}_{s_{t+1} \sim p} [V(s_{t+1})] $$ where we have the soft state value function:
$$V(s_t) = \mathbb{E}_{a_t\sim \pi}[Q(s_t, a_t) - \alpha \log\pi(a_t|s_t)] $$</description>
    </item>
    
  </channel>
</rss>